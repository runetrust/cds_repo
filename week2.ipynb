{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Johanne Sejrskild  \n",
    "Date: 10.08.2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code made by Rune Trust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Good afternoon*  \n",
    "Today we are going to work with variables and text as data. The green excercises will be highly linked to what you did yesterday with Anna. If you find them challenging use Annas powerpoint as a help or ask. If you want to challenge yourself, try and do them all without using any help. \n",
    "In the yellow and red excercises we will be working with text as data. Here we will work with litterary classics and exploring the language used. \n",
    "\n",
    "**Structure of the notebook:**  \n",
    "<span style=\"color:green\">\n",
    "Green excercises \n",
    "</span>\n",
    "<ul>\n",
    "  <li>Variables and storing data in them</li>\n",
    "  <li>Container variable types</li>\n",
    "  <li>Accessing elements</li>\n",
    "  <li>Quiz</li>\n",
    "</ul>\n",
    "\n",
    "<span style=\"color:yellow\">\n",
    "Yellow excercises \n",
    "</span>\n",
    "<ul>\n",
    "  <li>Build a lexicon of a word in a book of you choosing</li>\n",
    "  <li>Compare lengths of the books </li>\n",
    "</ul>\n",
    " \n",
    "\n",
    "<span style=\"color:red\">\n",
    "Red excercises\n",
    "</span>\n",
    "<ul>\n",
    "  <li>Find the most frequent words</li>\n",
    "  <li>Compare pronouns used in books written by male and female authors </li>\n",
    "</ul>\n",
    "  \n",
    "\n",
    "\n",
    "Start with the first excercise, and then continue in order. Feel free to work together, and see how far you can get.   \n",
    "The important thing is to learn, not to solve all the challenges!\n",
    "________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">\n",
    "<h2>\n",
    "Green excercises </h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and storing data in them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in the blanks:*\n",
    "\n",
    "Which variable does these data types belong to?  \n",
    "Whole numbers = Integers \n",
    "Decimal numbers = Float \n",
    "Collections of characters = String  \n",
    "True or False values = Boolean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add some values to the variables below and test if you are correct.  \n",
    "# you can use the type() function to check the data type of a variable.\n",
    "\n",
    "x = 1\n",
    "name = \"rune\"\n",
    "this_is_fun = True\n",
    "height = 180.5\n",
    "\n",
    "type(height)\n",
    "type(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Container variable types  \n",
    "Python provides several built-in container types, including lists, dictionaries, tuples, and sets. These containers can store collections of data and are essential for effective data manipulation.  \n",
    "\n",
    "*Lists* are ordered collections of items that can be changed (mutable). Lists are defined by square brackets [].  \n",
    "*Dictionaries* store key-value pairs, are unordered, and mutable. Defined by curly braces {}.  \n",
    "*Tuples* are ordered collections of items that cannot be changed (immutable). Defined by parentheses ().  \n",
    "*Sets* are unordered collections of unique items, mutable but items must be immutable. Defined by curly braces {} or the set() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list, dictionary, tuple and a set.\n",
    "\n",
    "# list\n",
    "list = [\"things\", \"stuffs\"]\n",
    "\n",
    "# dictionary\n",
    "dict = {\"things\": \"stuffs\"}\n",
    "\n",
    "# tuple\n",
    "tuple = (\"things\", \"stuffs\")\n",
    "\n",
    "# set\n",
    "set = {\"things\", \"stuffs\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing elements \n",
    "Access a value from each container variable you just created\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "things\n",
      "stuffs\n",
      "things\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# list - Access elements by index, starting at 0.\n",
    "print(list[0])\n",
    "\n",
    "# dictionary - Access values by their key.\n",
    "print(dict[\"things\"])\n",
    "\n",
    "# tuple - Access elements by index, just like lists.\n",
    "print(tuple[0])\n",
    "\n",
    "# set - Cannot access items by index because sets are unordered. but you can check if an item is in the set by using the 'in' keyword.\n",
    "print((\"things\" in set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz  \n",
    "\n",
    "1. Which of the following correctly adds a new element “orange” to the fruits list?\n",
    "\n",
    "fruits.add(orange)  \n",
    "fruits.append(\"orange\")  \n",
    "fruits.insert{\"orange\"}  \n",
    "fruits += [\"orange\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana']\n",
      "['apple', 'banana', 'orange']\n"
     ]
    }
   ],
   "source": [
    "fruits = [\"apple\", \"banana\"]\n",
    "print(fruits)\n",
    "fruits += [\"orange\"]\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: fruits.append(\"orange\"), and fruits += also works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How do you add a new key-value pair \"gender\": \"female\" to the person dictionary?\n",
    "\n",
    "person.add(\"gender\" = \"female\")  \n",
    "person[\"gender\"] = \"female\"  \n",
    "person.append(\"gender\": \"female\")  \n",
    "person.insert(\"gender\" = \"female\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: person[\"gender\"] = \"female\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Which of the following statements about tuples is true?\n",
    "\n",
    "Tuples are mutable.  \n",
    "You can add new elements to a tuple.  \n",
    "You access tuple elements by key.  \n",
    "Tuples are ordered and immutable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The last answer \"Tuples are ordered and immmutable\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What will be the result of adding an existing element to a set?\n",
    "\n",
    "The set will add another instance of the element.  \n",
    "The set will remain unchanged because it only holds unique elements.  \n",
    "The operation will result in an error.  \n",
    "The set will reorder its elements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.add(\"things\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The set will remain unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow\">\n",
    "<h2>\n",
    "Yellow excercises \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start on the *yellow excercises* you have to install and import the package containing all the litterary classics.  \n",
    "You will also get an example of how to build a lexicon of the use of the word \"whale\" in Moby Dick and the words surrounding it. \n",
    "\n",
    "So:  \n",
    "Run each cell underneath one at a time, in order. If something in one cell doesn't work right, it might be because you have overwritten a variable, so try going back and running all the previous cells again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [nltk][32m2/3\u001b[0m [nltk]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.2 nltk-3.9.1 regex-2025.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install the natural language toolkit package (nltk), which has a copy of the books.\n",
    "\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /home/ucloud/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the nltk package so that it is accessible to Python, and download a collection of books from Project Gutenberg\n",
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have installed and imported the books, but we want to extract one and do a bit of data cleeaning so we can look at the words used.  \n",
    "I have chosen to look at Moby Dick so lets find that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"mobydick\" which contains the text of the book.\n",
    "mobydick = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "mobydick = mobydick.lower()\n",
    "\n",
    "# remove the \"\\n\" and \"\\r\" characters, which indicate line breaks in the text (newlines)\n",
    "mobydick = mobydick.replace('\\n', ' ')\n",
    "mobydick = mobydick.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "mobydick = mobydick.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Why is it necessary to split the text into a list of words in order to do analysis on them?\n",
    "Answer: Because you otherwise would not be able to index and access each individual word correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable called \"concordance\", and fill it with every occurrence of the word \"whale\", and a few words preceeding and following \"whale\"\n",
    "lexicon = []\n",
    "for i, val in enumerate(mobydick):\n",
    "    if val == \"whale\":\n",
    "            lexicon.append(str(' '.join(mobydick[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at least, take the higgledy-piggledy whale statements, however authentic, in',\n",
       " 'that monstrous bulk of the whale or ork we have',\n",
       " \"paine, like as the wounded whale to shore flies thro'\",\n",
       " '--dryden\\'s annus mirabilis. \"while the whale is floating at the',\n",
       " \"jonas-in-the-whale. ... some say the whale can't open his mouth,\",\n",
       " 'i was told of a whale taken near shetland, that',\n",
       " 'that he caught once a whale in spitzbergen that was',\n",
       " 'and the breath of the whale is frequendy attended with',\n",
       " 'contemptible in the comparison. the whale is doubtless the largest',\n",
       " 'iceland in 1772. \"the spermacetti whale found by the nantuckois,',\n",
       " 'in the fishermen.\" --thomas jefferson\\'s whale memorial to the french',\n",
       " 'the nantucket whale-fishery. \"spain--a great whale stranded on the shores',\n",
       " 'to royal fish, which are whale and sturgeon. and these,',\n",
       " 'on high, up-spouted by a whale in air, to express',\n",
       " 'one.) \"the aorta of a whale is larger in the']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "lexicon[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many instances of the word \"whale\" were found\n",
    "len(lexicon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again, but this time let's just search for \"the whale\", not \"whale\" by itself.\n",
    "Try to comment each line of the code and explain what it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New empty list\n",
    "lexicon_twowords = []\n",
    "# For loop with two looping variables i and val\n",
    "# Enumerate makes the list instances into numbers that can be looped through using the i variable\n",
    "for i, val in enumerate(mobydick):\n",
    "    # If val is whale we look at the preceding word\n",
    "    if val == \"whale\":\n",
    "        if mobydick[i-1] == \"the\":\n",
    "            # if the preceding word is \"the\" we add the five words before and after the instance to the newly created lexiocn\n",
    "            lexicon_twowords.append(str(' '.join(mobydick[i-5:i+5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that monstrous bulk of the whale or ork we have',\n",
       " '--dryden\\'s annus mirabilis. \"while the whale is floating at the',\n",
       " \"jonas-in-the-whale. ... some say the whale can't open his mouth,\",\n",
       " 'and the breath of the whale is frequendy attended with',\n",
       " 'contemptible in the comparison. the whale is doubtless the largest',\n",
       " 'of the shipwreck of the whale ship essex of nantucket,',\n",
       " 'english miles. ... \"sometimes the whale shakes its tremendous tail',\n",
       " 'the known species of the whale tribe.\" --frederick debell bennett\\'s',\n",
       " 'while.\" --miriam coffin or the whale fisherman. \"the whale is',\n",
       " 'for your lives!\\'\" --wharton the whale killer. \"so be cheery,',\n",
       " 'my complaints-- no more the whale did me confine. \"with',\n",
       " 'that stifling hour, when the whale shall hold him in',\n",
       " 'jaws awaiting him; and the whale shoots-to all his ivory',\n",
       " \"the belly of hell'--when the whale grounded upon the ocean's\",\n",
       " 'blackness of the sea, the whale came breeching up towards']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the algorithm has found\n",
    "lexicon_twowords[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   Build a lexicon of a word in a book of you choosing\n",
    "\n",
    "\n",
    " Now, in the cell below, modify the code from above to search for a word in a book of your own choosing. Give your lexicon a meaningful name that is different from the ones above and comment your code so you understand what is happening each step of the way. \n",
    " But first lets have a look at the books you can choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code to build your own lexicon here, using the same method as above.\n",
    "# Create a variable called \"shakespeare\" which contains the text of the book.\n",
    "shakespeare = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "shakespeare = shakespeare.lower()\n",
    "\n",
    "# remove the \"\\n\" and \"\\r\" characters, which indicate line breaks in the text (newlines)\n",
    "shakespeare = shakespeare.replace('\\n', ' ')\n",
    "shakespeare = shakespeare.replace('\\r', ' ')\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "shakespeare = shakespeare.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'attendant. king. though yet of hamlet our deere brothers death',\n",
       " \"much i'th' sun queen. good hamlet cast thy nightly colour\",\n",
       " \"gentle and vnforc'd accord of hamlet sits smiling to my\",\n",
       " 'you, somthing touching the l[ord]. hamlet polon. marry, well bethought:',\n",
       " \"not stirre in this. now hamlet heare: it's giuen out,\",\n",
       " 'horatio and marcellus. mar. lord hamlet hor. heauen secure him',\n",
       " \"so poore a man as hamlet is, may doe t'\",\n",
       " 'sowing in my chamber, lord hamlet with his doublet all',\n",
       " 'and bring the gentlemen where hamlet is guil. heauens make',\n",
       " 'these qu. came this from hamlet to her pol. good',\n",
       " 'thus i did bespeake lord hamlet is a prince out',\n",
       " 'we will try it. enter hamlet reading on a booke.',\n",
       " 'we haue closely sent for hamlet hither, that he, as',\n",
       " 'not tell vs, what lord hamlet saide, we heard it',\n",
       " 'lights, lights, lights. exeunt. manet hamlet & horatio. ham. why',\n",
       " 'mine eares. no more sweet hamlet ham. a murderer, and',\n",
       " 'strongest workes. speake to her hamlet ham. how is it',\n",
       " 'you. good night mother. exit hamlet tugging in polonius. enter',\n",
       " 'you with some further ayde: hamlet in madnesse hath polonius',\n",
       " 'stowed gentlemen within. hamlet, lord hamlet ham. what noise? who',\n",
       " 'bring in my lord. enter hamlet and guildensterne. king. now',\n",
       " 'ham. for england? king. i hamlet ham. good king. so',\n",
       " 'mother king. thy louing father hamlet hamlet. my mother: father',\n",
       " 'this report of his did hamlet so envenom with his',\n",
       " 'sparke and fire of it: hamlet comes backe: what would',\n",
       " \"keepe close within your chamber, hamlet return'd, shall know you\",\n",
       " 'masse, i cannot tell. enter hamlet and horatio a farre',\n",
       " \"day that our last king hamlet o'recame fortinbras ham. how\",\n",
       " 'the very day, that young hamlet was borne, hee that',\n",
       " 'wonder-wounded hearers? this is i, hamlet the dane laer. the',\n",
       " 'pluck them asunder qu. hamlet, hamlet gen. good my lord',\n",
       " 'our proceeding be. exeunt. enter hamlet and horatio ham. so',\n",
       " \"heere proclaime was madnesse: was't hamlet wrong'd laertes? neuer hamlet.\",\n",
       " \"wrong'd laertes? neuer hamlet. if hamlet from himselfe be tane\",\n",
       " \"himselfe, do's wrong laertes, then hamlet does it not, hamlet\",\n",
       " 'then hamlet does it not, hamlet denies it: who does',\n",
       " \"his madnesse? if't be so, hamlet is of the faction\",\n",
       " 'wine vpon that table: if hamlet giue the first, or',\n",
       " 'queene carowses to thy fortune, hamlet ham. good madam king.',\n",
       " 'for. let foure captaines beare hamlet like a soldier to']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a variable called \"shake_lex\", and fill it with every occurrence of the word \"hamlet\", and a few words preceeding and following \"whale\"\n",
    "shake_lex = []\n",
    "for i, val in enumerate(shakespeare):\n",
    "    if val == \"hamlet\":\n",
    "            shake_lex.append(str(' '.join(shakespeare[i-5:i+5])))\n",
    "\n",
    "print(len(shake_lex))\n",
    "shake_lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare lengths of books\n",
    "\n",
    "We can use the command `len` to find how many items there are in a list. E.g., to find the number of words in the list called `mobydick`, from earlier, we can write: `len(mobydick)`. \n",
    "\n",
    "Use the starter code below to find out which book in the books included in `nltk` has the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austen-emma.txt: 158167\n",
      "austen-persuasion.txt: 83308\n",
      "austen-sense.txt: 118675\n",
      "bible-kjv.txt: 821133\n",
      "blake-poems.txt: 6845\n",
      "bryant-stories.txt: 45988\n",
      "burgess-busterbrown.txt: 15870\n",
      "carroll-alice.txt: 26443\n",
      "chesterton-ball.txt: 81598\n",
      "chesterton-brown.txt: 71626\n",
      "chesterton-thursday.txt: 57955\n",
      "edgeworth-parents.txt: 166070\n",
      "melville-moby_dick.txt: 212030\n",
      "milton-paradise.txt: 79659\n",
      "shakespeare-caesar.txt: 20459\n",
      "shakespeare-hamlet.txt: 29605\n",
      "shakespeare-macbeth.txt: 17741\n",
      "whitman-leaves.txt: 122070\n"
     ]
    }
   ],
   "source": [
    "# One way to do it: Print all the titles and numbers of words\n",
    "# starter code:\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "    # make all characters lowercase\n",
    "    book = book.lower()\n",
    "    \n",
    "    # remove the \"\\n\" and \"\\r\" characters, which indicate line breaks in the text (newlines)\n",
    "    book = book.replace('\\n', ' ')\n",
    "    book = book.replace('\\r', ' ')\n",
    "    \n",
    "    # split up the text into a long list of individual words\n",
    "    book = book.split()\n",
    "    print(f'{title}: {len(book)}')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional more advanced way to do it, for those with python experience up for a challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Another way to do it: Make a list of titles and a list of wordcounts, put it in a dataframe, then sort them based on wordcount\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# starter code:\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "titles = []\n",
    "numwords = []\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "    # make all characters lowercase\n",
    "    book = book.lower()\n",
    "    \n",
    "    # remove the \"\\n\" and \"\\r\" characters, which indicate line breaks in the text (newlines)\n",
    "    book = book.replace('\\n', ' ')\n",
    "    book = book.replace('\\r', ' ')\n",
    "    \n",
    "    # split up the text into a long list of individual words\n",
    "    book = book.split()\n",
    "    #print(f'{title}: {len(book)}')\n",
    "    titles.append(title)\n",
    "    numwords.append(len(book))\n",
    "\n",
    "data = {\"titles\": titles, \"numwords\": numwords}\n",
    "\n",
    "df = pd.DataFrame(data = data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>numwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bible-kjv.txt</td>\n",
       "      <td>821133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>212030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edgeworth-parents.txt</td>\n",
       "      <td>166070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austen-emma.txt</td>\n",
       "      <td>158167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>whitman-leaves.txt</td>\n",
       "      <td>122070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>118675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>austen-persuasion.txt</td>\n",
       "      <td>83308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chesterton-ball.txt</td>\n",
       "      <td>81598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton-paradise.txt</td>\n",
       "      <td>79659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chesterton-brown.txt</td>\n",
       "      <td>71626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterton-thursday.txt</td>\n",
       "      <td>57955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bryant-stories.txt</td>\n",
       "      <td>45988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shakespeare-hamlet.txt</td>\n",
       "      <td>29605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>carroll-alice.txt</td>\n",
       "      <td>26443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shakespeare-caesar.txt</td>\n",
       "      <td>20459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shakespeare-macbeth.txt</td>\n",
       "      <td>17741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burgess-busterbrown.txt</td>\n",
       "      <td>15870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blake-poems.txt</td>\n",
       "      <td>6845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     titles  numwords\n",
       "3             bible-kjv.txt    821133\n",
       "12   melville-moby_dick.txt    212030\n",
       "11    edgeworth-parents.txt    166070\n",
       "0           austen-emma.txt    158167\n",
       "17       whitman-leaves.txt    122070\n",
       "2          austen-sense.txt    118675\n",
       "1     austen-persuasion.txt     83308\n",
       "8       chesterton-ball.txt     81598\n",
       "13      milton-paradise.txt     79659\n",
       "9      chesterton-brown.txt     71626\n",
       "10  chesterton-thursday.txt     57955\n",
       "5        bryant-stories.txt     45988\n",
       "15   shakespeare-hamlet.txt     29605\n",
       "7         carroll-alice.txt     26443\n",
       "14   shakespeare-caesar.txt     20459\n",
       "16  shakespeare-macbeth.txt     17741\n",
       "6   burgess-busterbrown.txt     15870\n",
       "4           blake-poems.txt      6845"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = \"numwords\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "<h2>\n",
    "Red excercises\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most frequent words in the book you choose earlier\n",
    "\n",
    "`nltk` has a built-in function called `FreqDist` which counts up how many times each word in a text occurs. So, if you have a list called `words` which contains all the words in a book, you can find the frequencies of all of them by writing `freq = nltk.FreqDist(words)`. You can then get the ten most common words by writing `freq.most_common(10)` and so on.  \n",
    "What are the ten most common words in your book?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 992),\n",
       " ('and', 860),\n",
       " ('to', 683),\n",
       " ('of', 605),\n",
       " ('i', 520),\n",
       " ('my', 499),\n",
       " ('a', 497),\n",
       " ('you', 449),\n",
       " ('in', 377),\n",
       " ('it', 349)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starter code:\n",
    "\n",
    "book = nltk.corpus.gutenberg.raw('shakespeare-hamlet.txt')\n",
    "words = book.lower()\n",
    "    \n",
    "    # remove the \"\\n\" and \"\\r\" characters, which indicate line breaks in the text (newlines)\n",
    "words = words.replace('\\n', ' ')\n",
    "words = words.replace('\\r', ' ')\n",
    "\n",
    "words = words.split()\n",
    "\n",
    "freq = nltk.FreqDist(words)\n",
    "\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might not feel like the ten most frequent words are of any real value in a potential project for analysis or comparison. This is due to the fact that the most frequent words in our language is what we call *stopwords*. These words like \"a\" and \"the\" are so common in English, that they don't really tell us much about the text.   \n",
    "\n",
    "That is why we often remove \"stopwords\", that is, a list of the most common words in English, before e.g. counting frequencies.  \n",
    "\n",
    "\n",
    "There are several of these lists available, in [English]((https://gist.github.com/sebleier/554280)) as well as other languages, such as [Danish](https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b).  \n",
    "\n",
    "\n",
    "Below is some starter code to remove stopwords. Use these snippets to see what the most common words in your book is after removing these most common words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ham.', 337),\n",
       " ('haue', 171),\n",
       " ('shall', 106),\n",
       " ('thou', 101),\n",
       " ('king.', 96),\n",
       " ('hor.', 95),\n",
       " ('let', 94),\n",
       " ('good', 91),\n",
       " ('thy', 90),\n",
       " ('lord', 83)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of stopwords\n",
    "\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "# code to remove stopwords.\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "freq2 = nltk.FreqDist(words)\n",
    "\n",
    "freq2.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the pronouns used in books written by male and female authors\n",
    "\n",
    "**This could be an example of a project**  \n",
    "One could imagine that authors draw most inspiration from there own life and therefore write about characters resembeling themselves.  \n",
    "Investigate whether male and femate authors of novels write more pronouns they identify with themselves.  \n",
    "\n",
    "*Is there any evidence for this postulation in our data?*\n",
    "\n",
    "If you can, it would be neat to make a loop that goes through all books, and creates a dataframe that you afterwards can sort in to remove non-novels :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "# Example of structure:\n",
    "\n",
    "# Make a set of male and female pronouns (2 sets)\n",
    "male_pronouns = {\"he\", \"him\", \"his\", \"himself\"}\n",
    "female_pronouns = {\"she\", \"her\", \"hers\", \"herself\"}\n",
    "\n",
    "# Make a dictionary of all titles in the corpus and the authors gender (1 dictionary)\n",
    "author_genders = {\n",
    "    'austen-emma.txt': 'female',\n",
    "    'austen-persuasion.txt': 'female',\n",
    "    'austen-sense.txt': 'female',\n",
    "    'bible-kjv.txt': 'male',  # Traditionally male authorship, though it's a compilation\n",
    "    'blake-poems.txt': 'male',\n",
    "    'bryant-stories.txt': 'male',  # William Cullen Bryant\n",
    "    'burgess-busterbrown.txt': 'male',  # Thornton W. Burgess\n",
    "    'carroll-alice.txt': 'male',  # Lewis Carroll (Charles Lutwidge Dodgson)\n",
    "    'chesterton-ball.txt': 'male',\n",
    "    'chesterton-brown.txt': 'male',\n",
    "    'chesterton-thursday.txt': 'male',\n",
    "    'edgeworth-parents.txt': 'female',  # Maria Edgeworth\n",
    "    'melville-moby_dick.txt': 'male',\n",
    "    'milton-paradise.txt': 'male',\n",
    "    'shakespeare-caesar.txt': 'male',\n",
    "    'shakespeare-hamlet.txt': 'male',\n",
    "    'shakespeare-macbeth.txt': 'male',\n",
    "    'whitman-leaves.txt': 'male'\n",
    "}\n",
    "\n",
    "titles = []\n",
    "genders = []\n",
    "female_pronouns = []\n",
    "male_pronouns = []\n",
    "\n",
    "books = nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "print(books)\n",
    "# Make empty lists to store title, genders, number of female pronouns and number of male pronouns\n",
    "# Make a loop that iterates over each book, splits the text to words, counts the number of pronouns (hint: the code to remove stopwords), and append the information to the lists above\n",
    "# Make dataframe, fill it with the lists above, and print it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "for book in books:\n",
    "    words = book.lower()\n",
    "    words = words.replace('\\n', ' ')\n",
    "    words = words.replace('\\r', ' ')\n",
    "    words = words.split()\n",
    "    male_pronouns = [word for word in words if word in male_pronouns]\n",
    "    female_pronouns = [word for word in words if word in female_pronouns]\n",
    "\n",
    "print(female_pronouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss:*  \n",
    "What is your findings and what is the limitations of this project\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
